import { AIAnalysisResult, EducationalStandard, RigorAssessment } from '../types';\n\ninterface AnalysisResult {\n  consensusStandards: EducationalStandard[];\n  consensusRigorLevel: 'mild' | 'medium' | 'spicy';\n  standardsVotes: any;\n  rigorVotes: any;\n  confidenceScore: number;\n}\n\nexport class RigorAnalyzer {\n  /**\n   * Analyzes single AI engine result (optimized for single-engine processing)\n   */\n  analyzeSingleEngineResult(aiResult: { grok: AIAnalysisResult }): AnalysisResult {\n    console.log('Analyzing single engine (Grok) result');\n    \n    const grokResult = aiResult.grok;\n    \n    // Since we only have one engine, no voting is needed\n    const result: AnalysisResult = {\n      consensusStandards: grokResult.standards || [],\n      consensusRigorLevel: grokResult.rigor.level,\n      standardsVotes: {\n        'grok-only': {\n          count: 1,\n          sources: ['grok'],\n          standards: grokResult.standards || []\n        }\n      },\n      rigorVotes: {\n        [grokResult.rigor.level]: {\n          count: 1,\n          sources: ['grok'],\n          assessments: [grokResult.rigor]\n        }\n      },\n      confidenceScore: grokResult.rigor.confidence || 0.8\n    };\n    \n    console.log('Single engine analysis result:', result);\n    return result;\n  }\n\n  /**\n   * Consolidates multiple AI engine responses (for future multi-engine support)\n   */\n  consolidateResponses(aiResults: {\n    [key: string]: AIAnalysisResult;\n  }): AnalysisResult {\n    const engines = Object.keys(aiResults);\n    \n    if (engines.length === 1) {\n      // Single engine - use direct result\n      const singleResult = Object.values(aiResults)[0];\n      return this.analyzeSingleEngineResult({ grok: singleResult });\n    }\n    \n    // Multi-engine consensus (implement when needed)\n    const standardsList = engines.map(engine => aiResults[engine].standards);\n    const rigorList = engines.map(engine => aiResults[engine].rigor);\n    \n    const consensusStandards = this.voteOnStandards(standardsList);\n    const rigorVoting = this.voteOnRigorLevel(rigorList);\n    const confidenceScore = this.calculateConfidence(aiResults);\n\n    return {\n      consensusStandards: consensusStandards.standards,\n      consensusRigorLevel: rigorVoting.consensusLevel,\n      standardsVotes: consensusStandards.votes,\n      rigorVotes: rigorVoting.votes,\n      confidenceScore\n    };\n  }\n\n  private voteOnStandards(standardSets: EducationalStandard[][]): {\n    standards: EducationalStandard[];\n    votes: any;\n  } {\n    const standardCounts = new Map<string, {\n      standard: EducationalStandard;\n      count: number;\n      sources: string[];\n    }>();\n\n    // Count occurrences of each standard\n    standardSets.forEach((standards, index) => {\n      const sourceName = `engine_${index}`;\n      \n      standards.forEach(standard => {\n        const key = `${standard.code}-${standard.jurisdiction}`;\n        \n        if (standardCounts.has(key)) {\n          const existing = standardCounts.get(key)!;\n          existing.count++;\n          existing.sources.push(sourceName);\n        } else {\n          standardCounts.set(key, {\n            standard,\n            count: 1,\n            sources: [sourceName]\n          });\n        }\n      });\n    });\n\n    // Sort by count and take top standards\n    const sortedStandards = Array.from(standardCounts.values())\n      .sort((a, b) => b.count - a.count);\n\n    // Take standards that have majority votes or the most voted ones\n    const consensusStandards = sortedStandards\n      .filter(item => item.count >= Math.ceil(standardSets.length / 2))\n      .slice(0, 3)\n      .map(item => item.standard);\n\n    const votes = Object.fromEntries(\n      Array.from(standardCounts.entries()).map(([key, value]) => [\n        key,\n        {\n          count: value.count,\n          sources: value.sources,\n          standard: value.standard\n        }\n      ])\n    );\n\n    return {\n      standards: consensusStandards,\n      votes\n    };\n  }\n\n  private voteOnRigorLevel(rigorAssessments: RigorAssessment[]): {\n    consensusLevel: 'mild' | 'medium' | 'spicy';\n    votes: any;\n  } {\n    const rigorCounts = {\n      mild: 0,\n      medium: 0,\n      spicy: 0\n    };\n\n    const rigorSources = {\n      mild: [] as string[],\n      medium: [] as string[],\n      spicy: [] as string[]\n    };\n\n    // Count rigor level votes\n    rigorAssessments.forEach((rigor, index) => {\n      const sourceName = `engine_${index}`;\n      \n      if (rigor.level in rigorCounts) {\n        rigorCounts[rigor.level]++;\n        rigorSources[rigor.level].push(sourceName);\n      }\n    });\n\n    // Find the rigor level with the most votes\n    let consensusLevel: 'mild' | 'medium' | 'spicy' = 'mild';\n    let maxVotes = 0;\n\n    Object.entries(rigorCounts).forEach(([level, count]) => {\n      if (count > maxVotes) {\n        maxVotes = count;\n        consensusLevel = level as 'mild' | 'medium' | 'spicy';\n      }\n    });\n\n    const votes = {\n      mild: {\n        count: rigorCounts.mild,\n        sources: rigorSources.mild,\n        assessments: rigorAssessments.filter(r => r.level === 'mild')\n      },\n      medium: {\n        count: rigorCounts.medium,\n        sources: rigorSources.medium,\n        assessments: rigorAssessments.filter(r => r.level === 'medium')\n      },\n      spicy: {\n        count: rigorCounts.spicy,\n        sources: rigorSources.spicy,\n        assessments: rigorAssessments.filter(r => r.level === 'spicy')\n      }\n    };\n\n    return {\n      consensusLevel,\n      votes\n    };\n  }\n\n  private calculateConfidence(aiResults: { [key: string]: AIAnalysisResult }): number {\n    const engines = Object.keys(aiResults);\n    const results = Object.values(aiResults);\n    \n    if (engines.length === 1) {\n      return results[0].rigor.confidence || 0.8;\n    }\n    \n    // Calculate agreement between engines\n    const rigorLevels = results.map(r => r.rigor.level);\n    const uniqueLevels = new Set(rigorLevels);\n    const agreement = 1 - (uniqueLevels.size - 1) / (engines.length - 1);\n    \n    // Average individual confidence scores\n    const avgConfidence = results.reduce((sum, r) => sum + (r.rigor.confidence || 0.5), 0) / results.length;\n    \n    // Weighted confidence calculation\n    return Math.round((agreement * 0.6 + avgConfidence * 0.4) * 100) / 100;\n  }\n}\n\nexport const rigorAnalyzer = new RigorAnalyzer();\n