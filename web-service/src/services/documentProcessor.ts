import fs from 'fs';\nimport path from 'path';\nimport { spawn } from 'child_process';\nimport mammoth from 'mammoth';\nimport { ProcessingJob, ProcessingResult, QuestionResult } from '../types';\nimport { aiService } from './aiService';\nimport { rigorAnalyzer } from './rigorAnalyzer';\nimport { JobStore } from './jobStore';\n\nexport class DocumentProcessor {\n  private jobStore = new JobStore();\n\n  async processDocument(\n    jobId: string,\n    file: Express.Multer.File,\n    job: ProcessingJob\n  ): Promise<void> {\n    console.log(`Starting document processing for job ${jobId}`);\n    \n    try {\n      // Update job status\n      await this.jobStore.updateJobStatus(jobId, 'processing', 10, 'extracting_text');\n      \n      // Extract text from document\n      const extractedText = await this.extractText(file);\n      if (!extractedText) {\n        throw new Error('Failed to extract text from document');\n      }\n      \n      await this.jobStore.updateJobStatus(jobId, 'processing', 30, 'parsing_questions');\n      \n      // Parse questions from text\n      const questions = this.parseQuestions(extractedText);\n      if (questions.length === 0) {\n        throw new Error('No questions found in document');\n      }\n      \n      console.log(`Found ${questions.length} questions to analyze`);\n      await this.jobStore.updateJobStatus(jobId, 'processing', 50, 'ai_analysis');\n      \n      // Process each question with AI\n      const results: QuestionResult[] = [];\n      for (let i = 0; i < questions.length; i++) {\n        const question = questions[i];\n        const progress = 50 + Math.round((i / questions.length) * 40);\n        \n        await this.jobStore.updateJobStatus(\n          jobId, \n          'processing', \n          progress, \n          `analyzing_question_${i + 1}`\n        );\n        \n        try {\n          const aiResults = await aiService.analyzeQuestion(\n            question.text,\n            question.context,\n            job.jurisdictions,\n            job.focusStandards\n          );\n          \n          // Analyze results using rigor analyzer\n          const analysis = rigorAnalyzer.analyzeSingleEngineResult(aiResults);\n          \n          const questionResult: QuestionResult = {\n            questionNumber: question.number,\n            questionText: question.text,\n            context: question.context,\n            consensusStandards: analysis.consensusStandards,\n            consensusRigorLevel: analysis.consensusRigorLevel,\n            confidenceScore: analysis.confidenceScore,\n            aiResponses: [{\n              aiEngine: 'grok',\n              rigorLevel: aiResults.grok.rigor.level,\n              rigorJustification: aiResults.grok.rigor.justification,\n              confidence: aiResults.grok.rigor.confidence,\n              standardsIdentified: aiResults.grok.standards\n            }]\n          };\n          \n          results.push(questionResult);\n        } catch (error) {\n          console.error(`Failed to analyze question ${question.number}:`, error);\n          // Continue with other questions\n        }\n      }\n      \n      await this.jobStore.updateJobStatus(jobId, 'processing', 95, 'generating_summary');\n      \n      // Generate summary\n      const summary = this.generateSummary(results, job.startedAt);\n      \n      // Create final result\n      const finalResult: ProcessingResult = {\n        jobId,\n        customerId: job.customerId,\n        document: {\n          fileName: job.fileName,\n          fileSize: job.fileSize,\n          mimeType: job.mimeType,\n          processedAt: new Date()\n        },\n        results,\n        summary\n      };\n      \n      // Save results and mark as completed\n      await this.jobStore.saveJobResults(jobId, finalResult);\n      await this.jobStore.updateJobStatus(jobId, 'completed', 100, 'completed');\n      \n      console.log(`Document processing completed for job ${jobId}`);\n      \n      // Cleanup uploaded file\n      this.cleanupFile(file.path);\n      \n    } catch (error) {\n      console.error(`Document processing failed for job ${jobId}:`, error);\n      await this.jobStore.updateJobStatus(\n        jobId, \n        'failed', \n        0, \n        'failed', \n        error.message\n      );\n      \n      // Cleanup uploaded file\n      this.cleanupFile(file.path);\n      throw error;\n    }\n  }\n  \n  private async extractText(file: Express.Multer.File): Promise<string> {\n    const mimeType = file.mimetype;\n    \n    try {\n      if (mimeType === 'application/pdf') {\n        return await this.extractTextFromPDF(file.path);\n      } else if (\n        mimeType === 'application/msword' ||\n        mimeType === 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n      ) {\n        return await this.extractTextFromWord(file.path);\n      } else {\n        throw new Error(`Unsupported file type: ${mimeType}`);\n      }\n    } catch (error) {\n      console.error('Text extraction failed:', error);\n      throw error;\n    }\n  }\n  \n  private async extractTextFromPDF(filePath: string): Promise<string> {\n    return new Promise((resolve, reject) => {\n      const pythonPath = process.env.PYTHON_PATH || 'python3';\n      const scriptPath = path.resolve(__dirname, '../../scripts/extract_pdf_text.py');\n      \n      const pythonProcess = spawn(pythonPath, [scriptPath, filePath]);\n      \n      let output = '';\n      let errorOutput = '';\n      \n      pythonProcess.stdout.on('data', (data) => {\n        output += data.toString();\n      });\n      \n      pythonProcess.stderr.on('data', (data) => {\n        errorOutput += data.toString();\n      });\n      \n      pythonProcess.on('close', (code) => {\n        if (code === 0) {\n          try {\n            const result = JSON.parse(output);\n            if (result.success) {\n              resolve(result.text);\n            } else {\n              reject(new Error(result.error || 'PDF extraction failed'));\n            }\n          } catch (error) {\n            reject(new Error('Failed to parse PDF extraction result'));\n          }\n        } else {\n          reject(new Error(`PDF extraction failed: ${errorOutput}`));\n        }\n      });\n    });\n  }\n  \n  private async extractTextFromWord(filePath: string): Promise<string> {\n    try {\n      const result = await mammoth.extractRawText({ path: filePath });\n      return result.value;\n    } catch (error) {\n      throw new Error(`Word document extraction failed: ${error.message}`);\n    }\n  }\n  \n  private parseQuestions(text: string): Array<{\n    number: string;\n    text: string;\n    context: string;\n  }> {\n    const questions: Array<{ number: string; text: string; context: string }> = [];\n    \n    // Split text into lines and look for question patterns\n    const lines = text.split('\\n').map(line => line.trim()).filter(line => line.length > 0);\n    \n    // Look for numbered questions (1., 2., 1A, 2B, etc.)\n    const questionPattern = /^(\\d+[A-Z]?|[A-Z]\\d*)\\.?\\s+(.+)/i;\n    \n    let currentQuestion: { number: string; text: string; context: string } | null = null;\n    let contextLines: string[] = [];\n    \n    for (let i = 0; i < lines.length; i++) {\n      const line = lines[i];\n      const match = line.match(questionPattern);\n      \n      if (match) {\n        // Save previous question if exists\n        if (currentQuestion) {\n          currentQuestion.context = contextLines.join(' ');\n          questions.push(currentQuestion);\n        }\n        \n        // Start new question\n        currentQuestion = {\n          number: match[1],\n          text: match[2],\n          context: ''\n        };\n        contextLines = [];\n      } else if (currentQuestion) {\n        // Add to current question text or context\n        if (line.length > 10) { // Ignore very short lines\n          if (currentQuestion.text.length < 100) {\n            currentQuestion.text += ' ' + line;\n          } else {\n            contextLines.push(line);\n          }\n        }\n      } else {\n        // Collect context before first question\n        contextLines.push(line);\n      }\n    }\n    \n    // Save final question\n    if (currentQuestion) {\n      currentQuestion.context = contextLines.join(' ');\n      questions.push(currentQuestion);\n    }\n    \n    return questions.filter(q => q.text.length > 10); // Filter out very short \"questions\"\n  }\n  \n  private generateSummary(\n    results: QuestionResult[],\n    startTime: Date\n  ): ProcessingResult['summary'] {\n    const rigorDistribution = {\n      mild: 0,\n      medium: 0,\n      spicy: 0\n    };\n    \n    const standardsSet = new Set<string>();\n    \n    results.forEach(result => {\n      rigorDistribution[result.consensusRigorLevel]++;\n      result.consensusStandards.forEach(standard => {\n        standardsSet.add(standard.jurisdiction);\n      });\n    });\n    \n    const processingTime = this.formatProcessingTime(startTime, new Date());\n    \n    return {\n      totalQuestions: results.length,\n      rigorDistribution,\n      standardsCoverage: Array.from(standardsSet),\n      processingTime\n    };\n  }\n  \n  private formatProcessingTime(start: Date, end: Date): string {\n    const diff = end.getTime() - start.getTime();\n    const minutes = Math.floor(diff / 60000);\n    const seconds = Math.floor((diff % 60000) / 1000);\n    return `${minutes}m ${seconds}s`;\n  }\n  \n  private cleanupFile(filePath: string): void {\n    try {\n      if (fs.existsSync(filePath)) {\n        fs.unlinkSync(filePath);\n      }\n    } catch (error) {\n      console.warn('Failed to cleanup file:', filePath, error);\n    }\n  }\n}\n